\chapter{PROFILE Framework}\todo{Find better name for framework}
In this chapter a framework for engine or language profiling is formulated. The profile consists of a series of domains, which may hold one or more metrics. Metrics describe how well an engine scores in a single aspect, such as memory utilisation or input lag. 
Recall our claim that learning a new engine is akin to learning a new programming language. Therefore, the framework may be applied to game engines or languages.

\section{A Language PROFILE}
The \ac{PROFILE} framework covers four important domains of a language or game engine: 
\begin{itemize}
    \item Resource utilisation
    \item \ac{GPU} utilisation
    \item \ac{I/O}
    \item Usability
\end{itemize}
The resource utilisation domain should at least cover \ac{CPU} and memory utilisation. The \ac{CPU} utilisation metric was discussed in \chapref{benchmarks} and was measured using a set of benchmarks that emulate different aspects of workload on a running game. Memory was quickly mentioned, but not examined in great depth. Later research should focus on establishing tests for memory utilisation.

In general, later research should focus on establishing guidelines for \ac{GPU} utilisation, \ac{I/O} and Usability. \ac{GPU} utilisation is not discussed further in this report, but we outline approaches to the remaining domains in this section. 

The \ac{I/O} domain could be split in two metrics; file storage and input lag. For now, usability of the engine/language is a measure of the difficulty of learning and using the system. This is estimated using a static-analysis method called cognitive dimensions (see \secref{cog-dim}). Later work could introduce a variation of the discount method for language evaluation or expert-review methods that were discussed in \secref{language-evaluation}.

\section{Metrics} \label{sec:metrics}
Each domain is examined using a number of metrics. These metrics vary for each domain and are not necessarily comparable across domains or even inside domains, as is the case with the usability domain. The metrics for each domain is listed below. According to \cite{5962102} a game engine must consist of the subsystems illustrated in \figureref{engine-subsystes}. These subsystems are considered dimensions and are tested using different tests.

\begin{description}
    \item[\textbf{\ac{CPU} Utilisation}] concerns itself with the performance of the engine/language. Some engines make useful abstractions available at the cost of performance and other engines are so performant that they outperform general programming languages\tmc{A bit weak. Isn't memory performance also a thing? Which abstractions?}.
    \begin{itemize}
        \item Physics
        \item Artificial intelligence
        \item Scripting (Behaviour)
    \end{itemize}
    \item[\textbf{Usability}] is a measure of how difficult the engine/language is to learn and use. A number of relevant metrics have been selected from the cognitive dimensions methodology to be used here as metrics.
    \begin{itemize}
        \item Diffuseness/Terseness
        \item Hidden Dependencies
        \item Role-expressiveness
        \item Viscosity 
    \end{itemize}
    \item[\textbf{\ac{I/O} Utilisation}] is the engine/languages handling of \ac{I/O}. Here the efficacy is considered as well as the accessibility of the \ac{I/O} layer. Accessibility in this case is the range of available \ac{I/O} operations.
    \begin{itemize}
        \item Peripheral Input 
        \item File I/O
        \item Networking
    \end{itemize}
    \item[\textbf{\ac{GPU} Utilisation}] is a measure of how well the programming language/engine uses up the resources available on the \ac{GPU}. It also includes the accessibility of the \ac{GPU} resources from the programming language, i.e. how hard it is to move computations to the \ac{GPU}. 
    \begin{itemize}
        \item Rendering
        \item Shaders
        \item Lighting
        \item Accessibility
    \end{itemize}
\end{description}

\subsection{CPU Utilization}
Both artificial intelligence and scripting should be tested as shown in \ref{sec:microbenchmarks} and \ref{sec:macrobenchmarks}\todo{Refs skal nok specificeres noget mere}. This provides coverage of both AI and Scripting.
For physics, we suggest using three tests from \cite{physics-benchmark}. Namely collision computation performance, collision response accuracy and fixed constraint stability.
These benchmarks test both the accuracy and speed of physics performance for collision, constraint and force physics operations.
It may be worth also including a test for fabrics/hair.


\subsection{Usability}
The usability of a given language or engine is estimated using the cognitive dimensions framework (see \secref{cog-dim}). A number of dimensions of special interest are examined in depth and their relation to game development is highlighted. These dimensions have been selected because they favour fast development and problem mitigation \cite{ko2003development}. This is specially important in game development due to the its complex nature \cite{blow2004game}.

\subsubsection{Diffuseness/Terseness}
First among these dimensions is diffuseness or terseness. This dimension was selected based on the hypothesis that short programs are faster to write and easier to maintain, this is supported by the literature \cite{kemerer2009impact}. For languages and engines this quality manifests as the minimum necessary code size to achieve a certain goal or features that enable greater terseness.

An example of such a feature are variadic functions \cite{variadic:cppreference}. Such functions can take a variable number of arguments, thus eliminating the need for manually handling a number of cases that can be generalised. An example of this can be seen in \lstref{cpp-variadic}.

\begin{lstlisting}[style=cpp, caption={Variadic Function Example}, label=lst:cpp-variadic]
void simple_printf(const char* fmt...)
{
    va_list args;
    va_start(args, fmt);
 
    while (*fmt != '\0') {
        if (*fmt == 'd') {
            int i = va_arg(args, int);
            std::cout << i << '\n';
        } else if (*fmt == 'c') {
            // note automatic conversion to integral type
            int c = va_arg(args, int);
            std::cout << static_cast<char>(c) << '\n';
        } else if (*fmt == 'f') {
            double d = va_arg(args, double);
            std::cout << d << '\n';
        }
        ++fmt;
    }
    va_end(args);
}
\end{lstlisting}

The variadic feature can be seen on the first line of \lstref{cpp-variadic}. The three periods represent the arguments of variable length. The arguments are handled as a single list of arguments instead of separate arguments.

\subsubsection{Hidden Dependencies}
Some components in the code may be dependent on one another, which can cause programmer error if it is not apparent. Such a dependency is called a hidden dependency. Side effects on global variables are a typical example of hidden dependencies. Game engines and game development suffers from many hidden dependencies \cite{blow2004game, guana2015building, nystrom2014game}, this problem is sometimes referred to as \textit{cross-cutting} \cite{kiczales1997aspect}.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \tikzstyle{var}=[rectangle, draw, text width=6em, text centered]
        \tikzstyle{func}=[rectangle, draw, rounded corners, text width=6em, text centered, fill=green!20]
        \tikzstyle{line}=[draw, ->, >={Latex[width=2mm,length=2.5mm]}, thick]
        \tikzstyle{side}=[draw, dashed, ->, >={Latex[width=2mm,length=2.5mm]}, thick, red]
        
        \def \x {4}
        \def \y {-2}
        
        \node[var](arg)                     at (0,      0)      {Argument};
        \node[func, fill=green!20](fun)     at (0,      \y)     {Function with Side Effect};
        \node[var, fill=orange!40](global)  at (\x,     \y)     {Global Variable};
        \node[var](res)                     at (0,      2*\y)   {Result};
        \node[func, fill=blue!20](mod)      at (2*\x,   \y)     {Dependent Module};
        
        \path[line] (arg) -> (fun);
        \path[line] (fun) -> (res);
        \path[side] (fun) -> (global);
        \draw (global) edge (mod);
    \end{tikzpicture}
    \caption{Hidden Dependency caused by Side Effect}
    \label{fig:hid-dep-exmpl}
\end{figure}

\figureref{hid-dep-exmpl} depicts an example of a hidden dependency between \ttt{Function with Side Effect} and \ttt{Dependent Module}. The function takes some arguments and computes some result, however, during this computation the variable \ttt{Global Variable} is changed. This is problematic because the separate module \ttt{Dependent Module} depends on the global variable. When the error occurs in \ttt{Dependent Module}, the programmer can see that the error comes from the global variable, but not which functions or modules that change the variable. In order to find the fault, they must look for all places the variable is accessed in the code.

Since dependencies are rife in game engines \cite{blow2004game}, and arguably unavoidable, the question becomes how well these dependencies can be communicated to the developers. Features such as dependency diagrams and call graphs can alleviate this issue. Furthermore, these issues are also present at the language level \cite{kiczales1997aspect, green1996usability}.

\subsubsection{Role-expressiveness}
This dimension concerns itself with how descriptive individual components are, or how well they convey their role. In \acp{GPPL} this is partly controlled by the programmer, as abstraction can be used to improve role-expressivity, however in a game development context, especially when using game engines, developers are bound by the architecture provided by the engine or framework used.

An example of this is the \ttt{MonoBehaviour} class from Unity, which indicates that it is a behaviour. With a bit of context it can be determined that \ttt{Mono} in this case refers to the Mono runtime, thus the role of the class is clearly stated in the name; a behaviour which is executed in the Mono runtime. This stands in contrast to Godot's \ttt{PackedScene}, which is a template of a game object with related settings and assets. Such a \ttt{PackedScene} does not necessarily contain a scene, this name does not clearly communicate the objects role. Names such as \ttt{GameAsset} or \ttt{GameObjectTemplate} would be better. 

\subsubsection{Viscosity}
The development of games lends itself to iterative or agile software processes \cite{petrillo2010agility}. Therefore it is important to keep the cost of change low. Viscosity is a measure of the difficulty of change in a language or engine\footnote{The name comes from viscosity of fluids which is the fluid's resistance to local changes}.

The game development organisations examined by the authors of \cite{kasurinen2013applicable} were found to be using ad hoc development processes. However, the authors also found that game development organisations need iterative development processes.

\subsection{IO Utilization}
It is relevant to test the input and output performance because the time it takes to load game assets may be significant.
To test file \ac{I/O} speed we suggest applying the relevant benchmarks from \cite{Kernighan1998}.
These benchmarks test \ac{I/O} by reading and writing King James Bible (about 825000 words), in three of the following benchmarks: 
\begin{description}
    \item[File copying] Copies the input text directly to output. Depending on the language it may be done on a character or line basis. Similar to the Unix program \ttt{cat}.
    \item[Counting words] Counts lines, words and characters, and outputs the results. Akin to the Unix program \ttt{wc}.
    \item[Reversing a file] Reads a file on line basis into an array, then outputs the lines in the reverse order.
    \item[Sum] Reads a list of 100000 floating point numbers and computes their sum.
\end{description}

Both networking and input from keyboard/mouse, controller, etc should be tested as well. Especially when benchmarking an engine.
For networking, like the general scripting \ac{API} provided by the engine/language, both usability and performance should be checked. For usability, see section \ref{sec:api-evaluation}.

\subsubsection{API evaluation}\label{sec:api-evaluation}
\todo{Skal den her flyttes ud af metrics så vi kan bruge den flere gange? (network og hele engine)}

In \cite{api-evaluation} the author presents a few metrics for what makes up a good \ac{API}. These metrics include abstraction level, consistency etc. Following these metrics, several methods for evaluating \acs{API}s are presented. The methods differ slightly in focus. Some focus on the difficulty of initially learning the \ac{API}, one on the long term understanding, and some on how the users' mental model match the \ac{API}.

The difference between the methods means that it is possible to test an \ac{API} with different perspectives. As such there should be options for any kind of evaluation. 
This method can be applied to both the networking \ac{API} and the game engine \ac{API} as a whole.

\subsection{GPU Utilization}

1) We dont know shit here, so it's not well defined
2) the metrics, how do we imagine 

Graphics has not been our main focus in this report. 
As such this part of the framework is not as well defined as the rest.

The second dimenson, sharders, is at this  
