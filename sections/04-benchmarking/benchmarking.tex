\chapter{Benchmark Testing} \label{chap:benchmarks}
In this chapter a series of performance benchmarks are conducted. The benchmarks were intended to explore whether compilation technique has an effect on execution speed. In order to test this, the game engines Godot and CryEngine were used, as they both claim support for an interpreted (GDScript and Lua respectively), a \ac{JIT}-compiled (C\#) and a compiled (C++) language. Due to problems with both engines the focus switched and the chapter instead examines the performance of four different popular game engines; Unity, Unreal Engine, CryEngine and Godot.

We also wanted to explore if functional languages are slower than imperative languages. We do so to confirm or reject the popular belief we found that functional languages \dquote{suck} because they are slow \cite{pop:functional:sucks,pop:functional:slow} and hence cannot be used for game development. In this experiment we use the Arcadia plugin \cite{arcadia:github} for Unity and compare the execution speed of that with Mono C\# in Unity.

\input{sections/04-benchmarking/interpreted-vs-compiled.tex}
\input{sections/04-benchmarking/setup.tex}
\input{sections/04-benchmarking/micro-benchmarks.tex}
\input{sections/04-benchmarking/macro-benchmarks.tex}
\input{sections/04-benchmarking/further-work.tex}